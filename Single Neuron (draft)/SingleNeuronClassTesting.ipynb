{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the iris dataset from seaborn\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Filter the dataset to only include 'versicolor' and 'setosa' species\n",
    "filtered_iris = iris[iris['species'].isin(['versicolor', 'setosa'])]\n",
    "\n",
    "# Select only 'sepal_length' and 'sepal_width' variables\n",
    "filtered_iris = filtered_iris[['sepal_length', 'sepal_width', 'species']]\n",
    "\n",
    "# Label 'setosa' as 1 and 'versicolor' as -1\n",
    "filtered_iris['species'] = filtered_iris['species'].map({'setosa': 1, 'versicolor': -1})\n",
    "\n",
    "sepal_size_inputs = filtered_iris[['sepal_length', 'sepal_width']].to_numpy()\n",
    "target_species_output = filtered_iris['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SingleNeuronClass import SingleNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, None, 6]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,None,6]\n",
    "a_prev = a.copy()\n",
    "a.extend(b)\n",
    "print(a)\n",
    "print(a_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from progress.bar import ShadyBar\n",
    "#234567891123456789212345678931234567894123456789512345678961234567897123456789\n",
    "#                                python docstring limit: 72 characters |      \n",
    "#                                            python code limit: 79 characters |\n",
    "# test change\n",
    "class SingleNeuron(object):\n",
    "    \"\"\"\n",
    "    A class implementing single-neuron machine learning algorithms.\n",
    "    Implements the perceptron, linear regression classification, \n",
    "    and logistic regression classification.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    type_perceptron [class attribute] : string\n",
    "        Contains the keyword used to indicate that the algorithm\n",
    "        used by the instance is perceptron.\n",
    "\n",
    "    type_linear_regression_1D [class attribute] : string\n",
    "        Contains the keyword used to indicate that the algorithm\n",
    "        used by the instance is one-dimensional linear regression.\n",
    "    \n",
    "                                                                       |\n",
    "\n",
    "    Methods \n",
    "    -------\n",
    "    sign(cls, input_value) [class method]\n",
    "        Used as an activation function.\n",
    "\n",
    "    linear_1D(cls, input_value) [class method]\n",
    "        Returns 'input_value'. Used as an activation function.\n",
    "\n",
    "    perceptron_loss_function(cls, predicted_outputs, target_outputs)\n",
    "            [class method]\n",
    "        The loss function for the perceptron algorithm.\n",
    "\n",
    "    perceptron_stochastic_gradient(cls, predicted_output, target_output)\n",
    "            [class method]\n",
    "        The gradient of the perceptron's loss function when it employs\n",
    "        stochastic descent.\n",
    "\n",
    "    linear_regression_loss_function(cls, predicted_outputs, \n",
    "            target_outputs) [class method]\n",
    "        The loss function for the linear regression algorithm.\n",
    "\n",
    "    linear_regression_1D_stochastic_gradient(cls, predicted_output, \n",
    "            target_output) [class method]\n",
    "        The gradient of the one-dimensional linear regression loss \n",
    "        function when it employs stochastic descent.\n",
    "\n",
    "    preactivation(cls, input, weights, bias) [class method]\n",
    "        The preactivation function for the single neuron (dot product of\n",
    "        weights and input vector, plus bias)\n",
    "\n",
    "    __init__(self, data_dimension, model_type, weights=None, bias=None, \n",
    "            activation_function=None)\n",
    "        Initializes a model for a given dimensionality of training data\n",
    "        and model type. Can \"warm start\" with a user-provided weight and\n",
    "        bias, otherwise randomizes them. Can also provide an activation\n",
    "        function if the user wants one different from the default for \n",
    "        the model type.\n",
    "\n",
    "    predict_outputs(self, inputs, weights=None, bias=None, \n",
    "            use_current_weights_and_bias=True)\n",
    "        Outputs the model's predictions given an array of feature \n",
    "        vectors. \n",
    "\n",
    "    current_weights_and_bias(self)\n",
    "        Utility function for wrapping weights and bias in a single tuple.\n",
    "\n",
    "    perceptron_stochastic_gradient_update(self, input, target_output)\n",
    "        Updates the weights of the perceptron model using stochastic\n",
    "        descent.\n",
    "    \n",
    "    linear_regression_1D_stochastic_gradient_update(self, input, \n",
    "            target_output, learning_rate, training_data_length)\n",
    "        Updates the weights of the linear regression model using \n",
    "        stochastic descent.\n",
    "    \n",
    "    train(self, inputs, target_outputs, learning_rate=0.5, \n",
    "            num_epochs=50)\n",
    "        Trains the model (updates weights) using a batch of inputs and \n",
    "        target outputs.\n",
    "\n",
    "    reset_model(self)\n",
    "        Randomizes the weights and bias of the model.\n",
    "    \n",
    "    forget_previous_training(self)\n",
    "        Resets the weights and bias to their values before the most \n",
    "        recent training.\n",
    "                                                                       |\n",
    "    \"\"\"\n",
    "    type_perceptron = \"perceptron\"\n",
    "    type_linear_regression_1D = \"linear regression 1D\"\n",
    "\n",
    "    ## NEW (Needs section in class docstring)\n",
    "    type_logistic_regression_1D = \"logistic regression 1D\"\n",
    "\n",
    "    @classmethod\n",
    "    def sign(cls, input_value):\n",
    "        \"\"\" \n",
    "        Returns the sign of input_value (+1 if it's positive, -1 if\n",
    "        it's negative). \n",
    "        \"\"\"\n",
    "        if input_value >= 0:\n",
    "            return 1\n",
    "        else: \n",
    "            return -1\n",
    "        \n",
    "    @classmethod\n",
    "    def linear_1D(cls, input_value):\n",
    "        \"\"\" \n",
    "        Returns input_value. \n",
    "        \"\"\"\n",
    "        return input_value\n",
    "\n",
    "    @classmethod\n",
    "    def perceptron_loss_function(cls, \n",
    "                                 predicted_outputs, \n",
    "                                 target_outputs):\n",
    "        \"\"\" \n",
    "        The perceptron loss function given the perceptron's predictions\n",
    "        and the target outputs.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted_outputs : array_like\n",
    "            Perceptron's predictions. \n",
    "\n",
    "        target_outputs : array_like\n",
    "            Targets we`re training the perceptron to meet.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : float\n",
    "            The error of the prediction.\n",
    "        \"\"\"\n",
    "        return (1/4) * np.sum((predicted_outputs - target_outputs)**2)\n",
    "    \n",
    "    @classmethod\n",
    "    def perceptron_stochastic_gradient(cls, \n",
    "                                       predicted_output, \n",
    "                                       target_output):\n",
    "        \"\"\" \n",
    "        The gradient of the perceptron's loss function when it employs\n",
    "        stochastic descent.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted_output : array_like\n",
    "            Perceptron's predictions. \n",
    "\n",
    "        target_output : array_like\n",
    "            Targets we`re training the perceptron to meet.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gradient : float\n",
    "            The gradient of the loss function at the weights used to \n",
    "            calculate predicted_output\n",
    "        \"\"\"\n",
    "        return (1/2) * (predicted_output - target_output)\n",
    "\n",
    "    @classmethod\n",
    "    def linear_regression_loss_function(cls, \n",
    "                                        predicted_outputs, \n",
    "                                        target_outputs):\n",
    "        \"\"\" \n",
    "        The loss function for the linear regression algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted_outputs : array_like\n",
    "            Perceptron's predictions. \n",
    "\n",
    "        target_outputs : array_like\n",
    "            Targets we`re training the perceptron to meet.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : float\n",
    "            The error of the prediction.\n",
    "        \"\"\"\n",
    "        return (1/(2*target_outputs.size)) \\\n",
    "                * np.sum((predicted_outputs - target_outputs)**2)\n",
    "        \n",
    "    @classmethod\n",
    "    def linear_regression_1D_stochastic_gradient(cls, \n",
    "                                                 predicted_output, \n",
    "                                                 target_output, \n",
    "                                                 training_data_length):\n",
    "        \"\"\" \n",
    "        The gradient of the one-dimensional linear regression loss \n",
    "        function when it employs stochastic descent.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicted_output : array_like\n",
    "            The model's predictions. \n",
    "\n",
    "        target_output : array_like\n",
    "            Targets we`re training the model to meet.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gradient : float\n",
    "            The gradient of the loss function at the weights used to \n",
    "            calculate predicted_output\n",
    "\n",
    "        \"\"\"\n",
    "        return (1/training_data_length) * (predicted_output - target_output)\n",
    "\n",
    "    @classmethod\n",
    "    def preactivation(cls, input, weights, bias):\n",
    "        \"\"\" \n",
    "        The preactivation function for the single neuron (dot product of\n",
    "        weights and input vector, plus bias)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input : array_like\n",
    "            The vector input to the neuron.\n",
    "        \n",
    "        weights : array_like\n",
    "            The vector of weights of the model.\n",
    "        \n",
    "        bias : float\n",
    "            The bias of the model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        preactivation_value\n",
    "            The dot product of input and weights, plus the bias.\n",
    "        \"\"\"\n",
    "        if not (np.shape(input) == np.shape(weights)):\n",
    "            raise ValueError(\"Input vector must have the same shape as weights\"\n",
    "                + \"vector.\" + f\"{np.shape(input) = },  {np.shape(weights) = }\")\n",
    "        \n",
    "        return np.dot(input, weights) + bias\n",
    "    \n",
    "    ## NEW (needs section in class docstring)\n",
    "    @classmethod\n",
    "    def sigmoid(cls, input_value): \n",
    "        \"\"\" \n",
    "        Returns the value of the sigmoid function given input_value.\n",
    "        https://en.wikipedia.org/wiki/Sigmoid_function\n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-input_value))\n",
    "\n",
    "    @classmethod\n",
    "    def cross_entropy_loss_function(cls, \n",
    "                                    predicted_outputs,\n",
    "                                    target_outputs):\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "\n",
    "    def cross_entropy_loss(y_hat, y):\n",
    "    return - y*np.log(y_hat) - (1 - y)*np.log(1 - y_hat)\n",
    "\n",
    "    def __init__(self, \n",
    "                 data_dimension, \n",
    "                 model_type, \n",
    "                 weights=None, \n",
    "                 bias=None, \n",
    "                 activation_function=None):\n",
    "        \"\"\"\n",
    "        Initializes a model for a given dimensionality of training data\n",
    "        and model type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_dimension : int\n",
    "            The dimensionality of the feature vectors. Shouldn't be modified\n",
    "            after initialization.\n",
    "\n",
    "        model_type : str\n",
    "            The category of model. Used to select the activation function and \n",
    "            loss function. Shouldn't be modified post-initialization.\n",
    "\n",
    "        weights : array_like\n",
    "            Optional; \"warm start\" weights can be provided by the user, \n",
    "            otherwise weights are generated from a normal distribution.\n",
    "\n",
    "        bias : array_like\n",
    "            Optional; \"warm start\" bias can be provided by the user, \n",
    "            otherwise bias is generated from a normal distribution.\n",
    "        \n",
    "        activation_function : function\n",
    "            Optional; an arbitrary activation function can be provided by the \n",
    "            user, otherwise the standard function for the model type is \n",
    "            selected.\n",
    "        \"\"\"\n",
    "        if data_dimension < 1:\n",
    "            raise ValueError(f\"Provided data dimension is {data_dimension} \" \n",
    "                             + \"but it must be a positive integer.\")\n",
    "        self.data_dimension = data_dimension \n",
    "        # A single number for each feature vector has dimension 1, \n",
    "        # a 2D vector has dimension 2, etc.\n",
    "\n",
    "        self.model_type = model_type\n",
    "\n",
    "        if activation_function is None:\n",
    "            if self.model_type == SingleNeuron.type_perceptron:\n",
    "                self.activation_function = SingleNeuron.sign\n",
    "            elif self.model_type == SingleNeuron.type_linear_regression_1D:\n",
    "                self.activation_function = SingleNeuron.linear_1D\n",
    "            elif self.model_type == SingleNeuron.type_logistic_regression_1D:\n",
    "                self.activation_function = SingleNeuron.sigmoid\n",
    "        else:\n",
    "            self.activation_function = activation_function\n",
    "        \n",
    "        if weights is None:\n",
    "            self.weights = np.random.randn(data_dimension)\n",
    "            if data_dimension == 1:\n",
    "                # Unwrap weights to a scalar if there's only one weight\n",
    "                # This avoids additional checks in preactivation\n",
    "                self.weights = self.weights[0]\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        self.previous_weights = self.weights\n",
    "\n",
    "        if bias is None:\n",
    "            self.bias = np.random.randn()\n",
    "        else:\n",
    "            self.bias = bias\n",
    "        self.previous_bias = self.bias\n",
    "\n",
    "    def predict_outputs(self, \n",
    "                        inputs, \n",
    "                        use_current_weights_and_bias=True,\n",
    "                        weights=None, \n",
    "                        bias=None):\n",
    "        \"\"\" \n",
    "        Outputs the model's predictions given an array of feature \n",
    "        vectors. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : array_like\n",
    "            An array of feature vectors for the model to predict the outputs\n",
    "            of. Array dimensions incompatible with the dimensionality of the \n",
    "            model will raise a ValueError. Compatible array shapes are:\n",
    "                - Equal shape to that of the weights vector (single input)\n",
    "                - Final dimension equal to that of the weights vector (multiple\n",
    "                inputs)\n",
    "\n",
    "        use_current_weights_and_bias : boolean\n",
    "            Optional; if desired, the user can set this to false and provide \n",
    "            their own weights and bias whenever they require a prediction. By \n",
    "            default set to true, so this function uses the model's current \n",
    "            weights and bias.\n",
    "\n",
    "        weights : array_like\n",
    "            Optional; weight vector to use if the user desires to calculate \n",
    "            the output with weights other than the model's current weights.\n",
    "        \n",
    "        bias : float\n",
    "            Optional; bias to use if the user desires to calculate \n",
    "            the output with bias other than the model's current bias.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : array_like\n",
    "            The model's outputs corresponding to each input.\n",
    "        \"\"\"\n",
    "        if use_current_weights_and_bias:\n",
    "            weights = self.weights\n",
    "            bias = self.bias\n",
    "\n",
    "        if np.isscalar(inputs):\n",
    "            if self.data_dimension != 1:\n",
    "                raise ValueError(\"Mismatch between expected feature vector \"\n",
    "                    + f\"dimension ({self.data_dimension = }) and input \" \n",
    "                    + f\"shape ({np.shape(inputs) = }).\")\n",
    "            else:\n",
    "                return self.activation_function(\n",
    "                    SingleNeuron.preactivation(inputs, weights, bias))\n",
    "\n",
    "        elif inputs.shape == (self.data_dimension,):\n",
    "            return self.activation_function(\n",
    "                SingleNeuron.preactivation(inputs, weights, bias))\n",
    "        \n",
    "        elif inputs.shape[-1] == self.data_dimension    \\\n",
    "                or (self.data_dimension == 1 and inputs.ndim == 1):\n",
    "            return [self.activation_function(\n",
    "                        SingleNeuron.preactivation(input, weights, bias)) \n",
    "                    for input in inputs]\n",
    "\n",
    "        else: \n",
    "            raise ValueError(\"Mismatch between expected feature vector \"\n",
    "                + f\"dimension ({self.data_dimension = }) and input \" \n",
    "                + f\"shape ({np.shape(inputs) = }).\")\n",
    "    \n",
    "    def current_weights_and_bias(self):\n",
    "        \"\"\" \n",
    "        Utility function for wrapping weights and bias in a single tuple.\n",
    "        \"\"\"\n",
    "        return (self.weights.copy(), self.bias)\n",
    "    \n",
    "    def perceptron_stochastic_gradient_update(self, \n",
    "                                              input, \n",
    "                                              target_output):\n",
    "        \"\"\" \n",
    "        Updates the weights of the perceptron model using stochastic\n",
    "        descent. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input : array_like\n",
    "            The single input used to calculate the stochastic gradient at the\n",
    "            current weights.\n",
    "        \n",
    "        target_output : array_like\n",
    "            The single target output used to calculate the stochastic gradient\n",
    "            at the current weights.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gradient : float\n",
    "            The calculated gradient used to update the weights. \n",
    "\n",
    "        \"\"\"\n",
    "        gradient = SingleNeuron.perceptron_stochastic_gradient(\n",
    "                        self.predict_outputs(input), target_output)\n",
    "        self.weights -= gradient * input\n",
    "        self.bias -= gradient\n",
    "        return gradient\n",
    "\n",
    "    def linear_regression_1D_stochastic_gradient_update(self, \n",
    "                                                        input, \n",
    "                                                        target_output, \n",
    "                                                        learning_rate, \n",
    "                                                        training_data_length):\n",
    "        \"\"\" \n",
    "        Updates the weights of the linear regression model using \n",
    "        stochastic descent.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input : array_like\n",
    "            The single input used to calculate the stochastic gradient at the\n",
    "            current weights.\n",
    "        \n",
    "        target_output : array_like\n",
    "            The single target output used to calculate the stochastic gradient\n",
    "            at the current weights.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gradient : float\n",
    "            The calculated gradient used to update the weights.\n",
    "\n",
    "        \"\"\"\n",
    "        gradient = SingleNeuron.linear_regression_1D_stochastic_gradient(\n",
    "                                                self.predict_outputs(input), \n",
    "                                                target_output, \n",
    "                                                training_data_length)\n",
    "        self.weights -= learning_rate * gradient * input\n",
    "        self.bias -= learning_rate * gradient\n",
    "        return gradient\n",
    "        \n",
    "    def train(self, \n",
    "              inputs, \n",
    "              target_outputs, \n",
    "              learning_rate=0.5, \n",
    "              num_epochs=50):\n",
    "        \"\"\" \n",
    "        Trains the model (updates weights) using a batch of inputs and \n",
    "        target outputs.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : array_like\n",
    "            An array of feature vectors to train the model on. Must be as \n",
    "            many feature vectors as there are target outputs.\n",
    "        \n",
    "        target_outputs : array_like\n",
    "            An array of target outputs to compare the model's predictions to. \n",
    "            Must be as many targets as there are feature vectors.\n",
    "\n",
    "        learning_rate : float\n",
    "            Optional, and will not be used for the perceptron model; defines \n",
    "            the distance along the gradient by which the weights are adjusted \n",
    "            at every iteration.\n",
    "\n",
    "        num_epochs : int\n",
    "            Optional; defines the number of times the model looks at every \n",
    "            input-target pair. I.e. in each epoch the model looks at every\n",
    "            pair.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        loss_at_epoch : numpy.ndarray\n",
    "            An array of the value of the model's loss function at each epoch\n",
    "            in this training.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.previous_weights = np.copy(self.weights)\n",
    "        self.previous_bias = np.copy(self.bias)\n",
    "        weight_update = None\n",
    "        loss_function = None\n",
    "        \n",
    "        if self.model_type == SingleNeuron.type_perceptron:\n",
    "            weight_update = self.perceptron_stochastic_gradient_update\n",
    "            loss_function = SingleNeuron.perceptron_loss_function\n",
    "            \n",
    "        elif self.model_type == SingleNeuron.type_linear_regression_1D:\n",
    "            weight_update = lambda input, target : \\\n",
    "                self.linear_regression_1D_stochastic_gradient_update(\n",
    "                        input, target, learning_rate, len(target_outputs))\n",
    "            loss_function = SingleNeuron.linear_regression_loss_function\n",
    "\n",
    "        elif self.model_type == SingleNeuron.type_logistic_regression_1D:\n",
    "            \n",
    "\n",
    "        loss_at_epoch = np.empty(1 + num_epochs)\n",
    "        loss_at_epoch[0] = loss_function(self.predict_outputs(inputs),\n",
    "                                         target_outputs)\n",
    "\n",
    "        for epoch_index in ShadyBar(\n",
    "                \"Training\", \n",
    "                suffix=\"Epoch %(index)d / %(max)d\").iter(range(num_epochs)):\n",
    "            \n",
    "            for input, target_output in zip(inputs, target_outputs):\n",
    "                weight_update(input, target_output)\n",
    "                \n",
    "            loss_at_epoch[epoch_index+1] = loss_function(\n",
    "                    self.predict_outputs(inputs), target_outputs)\n",
    "\n",
    "        return loss_at_epoch\n",
    "\n",
    "    def reset_model(self):\n",
    "        \"\"\" \n",
    "        Randomizes the weights and bias of the model.\n",
    "        \"\"\"\n",
    "        if self.data_dimension == 1:\n",
    "            self.weights = np.random.randn()\n",
    "        else: \n",
    "            self.weights = np.random.randn(self.weights.shape)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def forget_previous_training(self):\n",
    "        \"\"\" \n",
    "        Resets the weights and bias to their values before the most recent\n",
    "        training.\n",
    "        \"\"\"\n",
    "        self.weights = np.copy(self.previous_weights)\n",
    "        self.bias = np.copy(self.previous_bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Model type: \" + self.model_type + \"\\n\" \\\n",
    "            + \"Weights: \" + self.weights + \" | Bias: \" + self.bias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model has diverged. Try turning down the learning rate!\nPrevious weights:0.9405012966033102 | Previous bias:0.6648128113156786 | Gradient:inf | \nEpoch:155 | Current input:5.6 | Current target output:3.0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m target_sepal_width_outputs_2 \u001b[38;5;241m=\u001b[39m filtered_iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msepal_width\u001b[39m\u001b[38;5;124m'\u001b[39m][filtered_iris[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m linreg_test_2 \u001b[38;5;241m=\u001b[39m SingleNeuron(\u001b[38;5;241m1\u001b[39m, model_type\u001b[38;5;241m=\u001b[39mSingleNeuron\u001b[38;5;241m.\u001b[39mtype_linear_regression_1D)\n\u001b[1;32m----> 4\u001b[0m linreg_test_2\u001b[38;5;241m.\u001b[39mtrain(sepal_length_inputs_2, target_sepal_width_outputs_2, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.059\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(sepal_length_inputs_2, \n\u001b[0;32m      7\u001b[0m             target_sepal_width_outputs_2, \n\u001b[0;32m      8\u001b[0m             color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmagenta\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m             label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversicolor flowers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClass.py:577\u001b[0m, in \u001b[0;36mSingleNeuron.train\u001b[1;34m(self, inputs, target_outputs, learning_rate, num_epochs)\u001b[0m\n\u001b[0;32m    574\u001b[0m         gradient \u001b[38;5;241m=\u001b[39m weight_update(\u001b[38;5;28minput\u001b[39m, target_output)\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)) \\\n\u001b[0;32m    576\u001b[0m                 \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias):\n\u001b[1;32m--> 577\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has diverged. Try turning down the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning rate!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m    579\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrevious weights:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprevious_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | Previous bias:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprevious_bias\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | Gradient:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgradient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m    582\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m    583\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent input:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent target output:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    587\u001b[0m     loss_at_epoch[epoch_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m loss_function(\n\u001b[0;32m    588\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(inputs), target_outputs)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_loss_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_history\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mValueError\u001b[0m: Model has diverged. Try turning down the learning rate!\nPrevious weights:0.9405012966033102 | Previous bias:0.6648128113156786 | Gradient:inf | \nEpoch:155 | Current input:5.6 | Current target output:3.0 "
     ]
    }
   ],
   "source": [
    "sepal_length_inputs_2 = filtered_iris['sepal_length'][filtered_iris['species'] == -1]\n",
    "target_sepal_width_outputs_2 = filtered_iris['sepal_width'][filtered_iris['species'] == -1]\n",
    "linreg_test_2 = SingleNeuron(1, model_type=SingleNeuron.type_linear_regression_1D)\n",
    "linreg_test_2.train(sepal_length_inputs_2, target_sepal_width_outputs_2, learning_rate=0.059, num_epochs=200)\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.scatter(sepal_length_inputs_2, \n",
    "            target_sepal_width_outputs_2, \n",
    "            color = \"magenta\",\n",
    "            label = \"versicolor flowers\")\n",
    "plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "plt.ylabel(\"sepal width [cm]\", fontsize = 15)\n",
    "plt.legend(fontsize = 15)\n",
    "plt.title(\"My Regression Data\", fontsize = 18)\n",
    "x = np.linspace(sepal_length_inputs_2.min(), sepal_length_inputs_2.max())\n",
    "plt.plot(x, linreg_test_2.weights*x + linreg_test_2.bias)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(1.20165045), 1.2421077232875881)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_test_2.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(nan), nan)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_test_2.current_weights_and_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.any(np.isinf(linreg_test_2.weights) or np.isnan(linreg_test_2.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length_inputs = filtered_iris['sepal_length'][filtered_iris['species'] == 1].to_numpy()\n",
    "target_sepal_width_outputs = filtered_iris['sepal_width'][filtered_iris['species'] == 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linreg_test.current_weights_and_bias() = (array(0.65200058), 0.005270935981000913)\n"
     ]
    }
   ],
   "source": [
    "linreg_test = SingleNeuron(1, model_type=SingleNeuron.type_linear_regression_1D)\n",
    "print(f\"{linreg_test.current_weights_and_bias() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linreg_test.current_weights_and_bias() = (array(-0.04385012), -1.4883181003581476)\n"
     ]
    }
   ],
   "source": [
    "linreg_test.reset_model()\n",
    "print(f\"{linreg_test.current_weights_and_bias() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10, 7))\n",
    "plt.scatter(sepal_length_inputs, \n",
    "            target_sepal_width_outputs, \n",
    "            color = \"lightseagreen\",\n",
    "            label = \"setosa flowers\")\n",
    "plt.xlabel(\"sepal length [cm]\", fontsize = 15)\n",
    "plt.ylabel(\"sepal width [cm]\", fontsize = 15)\n",
    "plt.legend(fontsize = 15)\n",
    "plt.title(\"My Regression Data\", fontsize = 18)\n",
    "x = np.linspace(sepal_length_inputs.min(), sepal_length_inputs.max())\n",
    "plt.plot(x, linreg_test.weights*x + linreg_test.bias)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linreg_test.predict(sepal_length_inputs[0]) = -1.7119537064741557\n",
      "target_sepal_width_outputs[0] = 3.5\n",
      "SingleNeuron.regression_1D_stochastic_gradient(test_prediction, test_true_val) = -5.211953706474156\n"
     ]
    }
   ],
   "source": [
    "print(f\"{linreg_test.predict(sepal_length_inputs[0]) = }\")\n",
    "test_prediction = linreg_test.predict(sepal_length_inputs[0])\n",
    "test_true_val = target_sepal_width_outputs[0]\n",
    "print(f\"{target_sepal_width_outputs[0] = }\")\n",
    "print(f\"{SingleNeuron.regression_1D_stochastic_gradient(test_prediction, test_true_val) = }\")\n",
    "# print(f\"{ = }\")\n",
    "# print(f\"{ = }\")\n",
    "# print(f\"{ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClass.py:221: RuntimeWarning: overflow encountered in square\n",
      "  * np.sum((predicted_outputs - target_outputs)**2)\n",
      "d:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClass.py:501: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  self.weights -= learning_rate * gradient * input\n",
      "d:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClass.py:502: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  self.bias -= learning_rate * gradient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.01858985e+001, 4.85157348e+109, 2.92561002e+217,             inf,\n",
       "                   inf,             inf,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan,             nan,\n",
       "                   nan,             nan,             nan])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_test.train(sepal_length_inputs, target_sepal_width_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_update0 = linreg_test.linear_regression_1D_stochastic_gradient_update(sepal_length_inputs[0], target_sepal_width_outputs[0], 0.5, 1)\n",
    "print(f\"{grad_update0 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad0 = SingleNeuron.linear_regression_1D_stochastic_gradient(linreg_test.predict_outputs(sepal_length_inputs[0]), target_sepal_width_outputs[0], 1)\n",
    "print(f\"{grad0 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0 = SingleNeuron.linear_regression_loss_function(linreg_test.predict_outputs(sepal_length_inputs[0]), target_sepal_width_outputs[0])\n",
    "print(f\"{loss0 = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_test.predict_outputs(sepal_length_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"{np.isscalar(sepal_length_inputs[0]) = }\")\n",
    "print(f\"{linreg_test.data_dimension = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.shape(sepal_length_inputs[0]) = }\")\n",
    "print(f\"{np.shape(5) = }\")\n",
    "print(f\"{np.shape(linreg_test.weights) = }\")\n",
    "print(f\"{np.isscalar(linreg_test.weights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.shape(sepal_length_inputs[0]) = }\")\n",
    "print(f\"{np.shape([sepal_length_inputs[0]]) = }\")\n",
    "print(f\"{np.shape(linreg_test.weights) = }\")\n",
    "print(f\"{np.shape([linreg_test.weights]) = }\")\n",
    "print(f\"{np.shape(sepal_size_inputs[0]) = }\")\n",
    "print(f\"{np.shape([sepal_size_inputs[0]]) = }\")\n",
    "print(f\"{np.shape(model.weights) = }\")\n",
    "print(f\"{np.shape([model.weights]) = }\")\n",
    "print(f\"{np.shape(np.random.randn(2)) = }\")\n",
    "print(f\"{np.shape(np.asarray(sepal_length_inputs[0])) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleNeuron(sepal_size_inputs.shape[1], model_type=\"perceptron\")\n",
    "model.current_weights_and_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.perceptron_stochastic_gradient_update(sepal_size_inputs[4], target_species_output[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(sepal_size_inputs, target_species_output, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.perceptron_stochastic_gradient_update(sepal_size_inputs[-1], target_species_output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.predict_outputs(sepal_size_inputs[0]) = }, but  {target_species_output[0] = }\")\n",
    "gradient = SingleNeuron.perceptron_stochastic_gradient(model.predict_outputs(sepal_size_inputs[0]), target_species_output[0])\n",
    "print(f\"{gradient = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_model()\n",
    "model.current_weights_and_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs = model.predict_outputs(sepal_size_inputs)\n",
    "print(f\"{SingleNeuron.perceptron_loss_function(predicted_outputs, target_species_output) = }\")\n",
    "#hmm... why is this consistently outputting 50...\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(sepal_size_inputs[target_species_output == 1, 0], \n",
    "            sepal_size_inputs[target_species_output == 1, 1], \n",
    "            color=\"magenta\", label=\"Setosa (1)\")\n",
    "plt.scatter(sepal_size_inputs[target_species_output == -1, 0], \n",
    "            sepal_size_inputs[target_species_output == -1, 1], \n",
    "            color=\"green\", label=\"Versicolor (-1)\")\n",
    "x = np.linspace(sepal_size_inputs[:,0].min(), sepal_size_inputs[:,0].max())\n",
    "plt.plot(x, (-model.weights[0]*x - model.bias) / model.weights[1]) \n",
    "\n",
    "#Oh if it's frequently outputting 50 because it's getting 50 values wrong most of the time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.predict_outputs(sepal_size_inputs[0]) = }\")\n",
    "print(f\"{model.predict_outputs(sepal_size_inputs[0:3]) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preactivation_value = SingleNeuron.preactivation(sepal_size_inputs[0], model.weights, model.bias)\n",
    "print(f\"{preactivation_value = }\")\n",
    "print(f\"{model.activation_function(preactivation_value) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{[sepal_size for sepal_size in sepal_size_inputs[0,:]] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{SingleNeuron.preactivation(sepal_size_inputs[0], model.weights, model.bias) = }\")\n",
    "print(f\"{np.dot(sepal_size_inputs[0], model.weights) + model.bias = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{SingleNeuron.sign(-0.00001) = }\")\n",
    "print(f\"{SingleNeuron.linear_1D(523/100) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs[target_species_output==1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.current_weights_and_bias() = }\")\n",
    "[current_weights, current_bias] = model.current_weights_and_bias()\n",
    "print(f\"{sepal_size_inputs[1] = }\")\n",
    "print(f\"{SingleNeuron.preactivation(sepal_size_inputs[1], current_weights, current_bias) = }\")\n",
    "preactivation_value = SingleNeuron.preactivation(sepal_size_inputs[1], current_weights, current_bias)\n",
    "print(f\"{model.activation_function(preactivation_value) = }\")\n",
    "print(f\"{model.predict_outputs(sepal_size_inputs[1]) = }\")\n",
    "inputs = sepal_size_inputs\n",
    "activation_values = [model.activation_function(SingleNeuron.preactivation(input, current_weights, current_bias)) for input in inputs]\n",
    "print(f\"{activation_values = }\")\n",
    "print(f\"{model.predict_outputs(inputs) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(SingleNeuron.sign(SingleNeuron.preactivation(sepal_size_inputs[1], model.weights, model.bias)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sepal_size_inputs[1] = }\")\n",
    "print(f\"{np.shape(sepal_size_inputs[1]) = } but {np.shape(model.weights) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleNeuron.sign(np.float64(3.3034947687319463))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{SingleNeuron.sign(0) = }\")\n",
    "print(f\"{SingleNeuron.linear_1D(8.3) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sepal_size_inputs.shape = }\")\n",
    "print(f\"{sepal_size_inputs.shape[1] = }\")\n",
    "print(f\"{sepal_size_inputs[1] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3)\n",
    "type(x) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xval in x:\n",
    "    print(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2))\n",
    "b = np.copy(a)\n",
    "a[0,0] = 1\n",
    "a[1,0] = 2\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.copy(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([A for A in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMOR438_base1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
