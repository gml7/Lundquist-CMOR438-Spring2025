{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the iris dataset from seaborn\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Filter the dataset to only include 'versicolor' and 'setosa' species\n",
    "filtered_iris = iris[iris['species'].isin(['versicolor', 'setosa'])]\n",
    "\n",
    "# Select only 'sepal_length' and 'sepal_width' variables\n",
    "filtered_iris = filtered_iris[['sepal_length', 'sepal_width', 'species']]\n",
    "\n",
    "# Label 'setosa' as 1 and 'versicolor' as -1\n",
    "filtered_iris['species'] = filtered_iris['species'].map({'setosa': 1, 'versicolor': -1})\n",
    "\n",
    "sepal_size_inputs = filtered_iris[['sepal_length', 'sepal_width']].to_numpy()\n",
    "target_species_output = filtered_iris['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "#234567891123456789212345678931234567894123456789512345678961234567897123456789\n",
    "#                                python docstring limit: 72 characters |      \n",
    "#                                            python code limit: 79 characters |\n",
    "# test change\n",
    "class SingleNeuron(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a single neuron (in the machine learning \n",
    "    sense).\n",
    "\n",
    "    Design notes: the model type and the activation function are \n",
    "    intended to be immutable, though of course python still lets you mutate them.\n",
    "    \"\"\"\n",
    "    type_perceptron = \"perceptron\"\n",
    "    type_linear_regression_1D = \"linear regression 1D\"\n",
    "\n",
    "    def sign(input_value):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        if input_value >= 0:\n",
    "            return 1\n",
    "        else: \n",
    "            return -1\n",
    "        \n",
    "    def linear_1D(input_value):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        return input_value\n",
    "    \n",
    "    # default_activation_function = sign\n",
    "\n",
    "    # def test_for_matching_ndarrays(var_1, var_2):\n",
    "    #     return type(var_1) != np.ndarray or type(var_2) != np.ndarray \\\n",
    "    #            or var_1.shape != var_1.shape\n",
    "\n",
    "    def perceptron_loss_function(predicted_outputs, \n",
    "                                 target_outputs):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        # if SingleNeuron.test_for_matching_ndarrays(predicted_values, true_values) == False:\n",
    "        #     raise TypeError\n",
    "        return (1/4) * np.sum((predicted_outputs - target_outputs)**2)\n",
    "    \n",
    "    def perceptron_stochastic_gradient(predicted_output, \n",
    "                                       target_output):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (1/2) * (predicted_output - target_output)\n",
    "\n",
    "    def linear_regression_loss_function(predicted_outputs, \n",
    "                                        target_outputs):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        # if SingleNeuron.test_for_matching_ndarrays(predicted_values, true_values) == False:\n",
    "        #     raise TypeError\n",
    "        return (1/(2*target_outputs.size)) * np.sum((predicted_outputs - target_outputs)**2)\n",
    "        \n",
    "    def linear_regression_1D_stochastic_gradient(predicted_output, \n",
    "                                                 target_output, \n",
    "                                                 training_data_length):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (1/training_data_length) * (predicted_output - target_output)\n",
    "\n",
    "    def preactivation(input_vector, weights, bias):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        assert np.shape(input) is np.shape(weights), \\\n",
    "                \"Input vector must have the same shape as weights vector.\" \\\n",
    "                + f\"{np.shape(input) = },  {np.shape(weights) = }\"\n",
    "        return np.dot(input, weights) + bias\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_dimension, \n",
    "                 model_type, \n",
    "                 weights=None, \n",
    "                 bias=None, \n",
    "                 activation_function=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data_dimension = data_dimension \n",
    "        # A single number for each feature vector has dimension 1, \n",
    "        # a 2D vector has dimension 2, etc.\n",
    "\n",
    "        self.model_type = model_type\n",
    "\n",
    "        if activation_function is None:\n",
    "            if self.model_type == SingleNeuron.type_perceptron:\n",
    "                self.activation_function = SingleNeuron.sign\n",
    "            elif self.model_type == SingleNeuron.type_linear_regression_1D:\n",
    "                self.activation_function = SingleNeuron.linear_1D\n",
    "        else:\n",
    "            self.activation_function = activation_function\n",
    "        \n",
    "        if weights is None:\n",
    "            self.weights = np.random.randn(data_dimension)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        self.previous_weights = self.weights\n",
    "\n",
    "        if bias is None:\n",
    "            self.bias = np.random.randn()\n",
    "        else:\n",
    "            self.bias = bias\n",
    "        self.previous_bias = self.bias\n",
    "\n",
    "    def predict_outputs(self, \n",
    "                        inputs, \n",
    "                        weights=None, \n",
    "                        bias=None, \n",
    "                        use_current_weights_and_bias=True):\n",
    "        \"\"\" \n",
    "        sets \"use_current_weights_and_bias\" to False to prevent extra assignments in predict_single_output\n",
    "        \"\"\"\n",
    "        if use_current_weights_and_bias:\n",
    "            weights = self.weights\n",
    "            bias = self.bias\n",
    "\n",
    "        assert (np.isscalar(inputs) and self.data_dimension == 1) \\\n",
    "                or ((not np.isscalar(inputs)) and inputs.shape[-1] == self.data_dimension), \\\n",
    "                    \"Prediction: mismatch between expected feature vector \" \\\n",
    "                        + f\"\\ndimension ({self.data_dimension = }) and input \" \\\n",
    "                        + f\"shape ({np.shape(inputs) = }).\"\n",
    "        \n",
    "        if ((not np.isscalar(inputs)) and len(inputs.shape) == 1):\n",
    "            return self.activation_function(SingleNeuron.preactivation(inputs, weights, bias))\n",
    "        else:\n",
    "            return [self.activation_function(SingleNeuron.preactivation(input, weights, bias)) for input in inputs]\n",
    "    \n",
    "    def current_weights(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return self.weights.copy()\n",
    "    \n",
    "    def current_bias(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return self.bias\n",
    "\n",
    "    def current_weights_and_bias(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (self.weights.copy(), self.bias)\n",
    "    \n",
    "    def perceptron_stochastic_gradient_update(self, \n",
    "                                              input, \n",
    "                                              target_output, \n",
    "                                              learning_rate=None):\n",
    "        \"\"\" \n",
    "        learning_rate does nothing and is just for making it more uniform to pass around update functions\n",
    "        \"\"\"\n",
    "        gradient = SingleNeuron.perceptron_stochastic_gradient(self.predict_multiple_outputs(input_vector), target_output)\n",
    "        self.weights -= gradient * input_vector\n",
    "        self.bias -= gradient\n",
    "        return gradient\n",
    "\n",
    "    def linear_regression_1D_stochastic_gradient_update(self, \n",
    "                                                        input, \n",
    "                                                        target_output, \n",
    "                                                        learning_rate):\n",
    "        gradient = SingleNeuron.linear_regression_1D_stochastic_gradient(self.predict_outputs(input), target_output)\n",
    "        self.weights -= learning_rate * gradient * input\n",
    "        self.bias -= learning_rate * gradient\n",
    "        return gradient\n",
    "        \n",
    "    def train(self, \n",
    "              inputs, \n",
    "              target_outputs, \n",
    "              learning_rate=0.5, \n",
    "              num_epochs=50):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        self.previous_weights = np.copy(self.weights)\n",
    "        self.previous_bias = np.copy(self.bias.copy())\n",
    "        # if self.model_type != SingleNeuron.type_perceptron and (learning_rate == None or epochs == None):\n",
    "        #     raise ValueError(\"learning_rate and epochs must be specified for non-perceptron models\")\n",
    "        weight_bias_update = None\n",
    "        loss_function = None\n",
    "        if self.model_type is SingleNeuron.type_perceptron:\n",
    "            weight_bias_update = self.perceptron_stochastic_gradient_update\n",
    "            loss_function = SingleNeuron.perceptron_loss_function\n",
    "        elif self.model_type is SingleNeuron.type_linear_regression_1D:\n",
    "            weight_bias_update = self.linear_regression_1D_stochastic_gradient_update\n",
    "            loss_function = SingleNeuron.linear_regression_loss_function\n",
    "\n",
    "        loss_at_epoch = np.empty(1 + num_epochs)\n",
    "        loss_at_epoch[0] = loss_function(self.predict_multiple_outputs(inputs), target_outputs)\n",
    "\n",
    "        for epoch_index in range(num_epochs):\n",
    "            for input, target_output in zip(inputs, target_outputs):\n",
    "                weight_bias_update(input, target_output, learning_rate)\n",
    "            loss_at_epoch[epoch_index+1] = loss_function(self.predict_multiple_outputs(inputs), target_outputs)\n",
    "\n",
    "        return loss_at_epoch\n",
    "\n",
    "    def reset_model(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(self.weights.size)\n",
    "        self.bias = np.random.randn()\n",
    "\n",
    "    def forget_previous_training(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        self.weights = np.copy(self.previous_weights)\n",
    "        self.bias = np.copy(self.previous_bias)\n",
    "\n",
    "# todo\n",
    "    def __repr__(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "# might not be necessary\n",
    "    # def __call__(self):\n",
    "    #     return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.1161227 , -0.47691097]), -0.700145515872466)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SingleNeuron(sepal_size_inputs.shape[1], model_type=\"perceptron\")\n",
    "model.current_weights_and_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.08398299, -1.33978341]), -0.09676752179223268)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_model()\n",
    "model.current_weights_and_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input vector must have the same shape as weights vector.np.shape(input) = (),  np.shape(weights) = (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predicted_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_outputs(sepal_size_inputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mSingleNeuron\u001b[39m.\u001b[39mperceptron_loss_function(predicted_outputs,\u001b[39m \u001b[39mtarget_species_output)\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#hmm... why is this consistently outputting 50...\u001b[39;00m\n",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function(SingleNeuron\u001b[39m.\u001b[39mpreactivation(inputs, weights, bias))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function(SingleNeuron\u001b[39m.\u001b[39mpreactivation(\u001b[39minput\u001b[39m, weights, bias)) \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs]\n",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreactivation\u001b[39m(input_vector, weights, bias):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m) \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mshape(weights), \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mInput vector must have the same shape as weights vector.\u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m)\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m,  \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(weights)\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(\u001b[39minput\u001b[39m, weights) \u001b[39m+\u001b[39m bias\n",
      "\u001b[1;31mAssertionError\u001b[0m: Input vector must have the same shape as weights vector.np.shape(input) = (),  np.shape(weights) = (2,)"
     ]
    }
   ],
   "source": [
    "predicted_outputs = model.predict_outputs(sepal_size_inputs)\n",
    "print(f\"{SingleNeuron.perceptron_loss_function(predicted_outputs, target_species_output) = }\")\n",
    "#hmm... why is this consistently outputting 50...\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(sepal_size_inputs[target_species_output == 1, 0], \n",
    "            sepal_size_inputs[target_species_output == 1, 1], \n",
    "            color=\"magenta\", label=\"Setosa (1)\")\n",
    "plt.scatter(sepal_size_inputs[target_species_output == -1, 0], \n",
    "            sepal_size_inputs[target_species_output == -1, 1], \n",
    "            color=\"green\", label=\"Versicolor (-1)\")\n",
    "x = np.linspace(sepal_size_inputs[:,0].min(), sepal_size_inputs[:,0].max())\n",
    "plt.plot(x, (-model.weights[0]*x - model.bias) / model.weights[1]) \n",
    "\n",
    "#Oh it's constantly outputting 50 because it's getting 50 values wrong most of the time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.predict_single_output(sepal_size_inputs[0]) = }\")\n",
    "print(f\"{model.predict_multiple_outputs(sepal_size_inputs[0:3]) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preactivation_value = SingleNeuron.preactivation(sepal_size_inputs[0], model.weights, model.bias)\n",
    "print(f\"{preactivation_value = }\")\n",
    "print(f\"{model.activation_function(preactivation_value) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{[sepal_size for sepal_size in sepal_size_inputs[0,:]] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{SingleNeuron.preactivation(sepal_size_inputs[0], model.weights, model.bias) = }\")\n",
    "print(f\"{np.dot(sepal_size_inputs[0], model.weights) + model.bias = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{SingleNeuron.sign(-0.00001) = }\")\n",
    "print(f\"{SingleNeuron.linear_1D(523/100) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_size_inputs[target_species_output==1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{model.current_weights_and_bias() = }\")\n",
    "[current_weights, current_bias] = model.current_weights_and_bias()\n",
    "print(f\"{sepal_size_inputs[1] = }\")\n",
    "print(f\"{SingleNeuron.preactivation(sepal_size_inputs[1], current_weights, current_bias) = }\")\n",
    "preactivation_value = SingleNeuron.preactivation(sepal_size_inputs[1], current_weights, current_bias)\n",
    "print(f\"{model.activation_function(preactivation_value) = }\")\n",
    "print(f\"{model.predict_outputs(sepal_size_inputs[1]) = }\")\n",
    "inputs = sepal_size_inputs\n",
    "activation_values = [model.activation_function(SingleNeuron.preactivation(input, current_weights, current_bias)) for input in inputs]\n",
    "print(f\"{activation_values = }\")\n",
    "print(f\"{model.predict_outputs(inputs) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input vector must have the same shape as weights vector.np.shape(input) = (),  np.shape(weights) = (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [(SingleNeuron\u001b[39m.\u001b[39msign(SingleNeuron\u001b[39m.\u001b[39mpreactivation(sepal_size_inputs[\u001b[39m1\u001b[39m], model\u001b[39m.\u001b[39mcurrent_weights(), model\u001b[39m.\u001b[39mcurrent_bias())))]\n",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 17\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreactivation\u001b[39m(input_vector, weights, bias):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m) \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mshape(weights), \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mInput vector must have the same shape as weights vector.\u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m)\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m,  \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(weights)\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X21sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(\u001b[39minput\u001b[39m, weights) \u001b[39m+\u001b[39m bias\n",
      "\u001b[1;31mAssertionError\u001b[0m: Input vector must have the same shape as weights vector.np.shape(input) = (),  np.shape(weights) = (2,)"
     ]
    }
   ],
   "source": [
    "[(SingleNeuron.sign(SingleNeuron.preactivation(sepal_size_inputs[1], model.current_weights(), model.current_bias())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SingleNeuron.sign(np.float64(3.3034947687319463))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleNeuron.sign(0) = 1\n",
      "SingleNeuron.linear_1D(8.3) = 8.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"{SingleNeuron.sign(0) = }\")\n",
    "print(f\"{SingleNeuron.linear_1D(8.3) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_size_inputs.shape = (100, 2)\n",
      "sepal_size_inputs.shape[1] = 2\n",
      "sepal_size_inputs[1] = array([4.9, 3. ])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sepal_size_inputs.shape = }\")\n",
    "print(f\"{sepal_size_inputs.shape[1] = }\")\n",
    "print(f\"{sepal_size_inputs[1] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(3)\n",
    "type(x) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xval in x:\n",
    "    print(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2))\n",
    "b = np.copy(a)\n",
    "a[0,0] = 1\n",
    "a[1,0] = 2\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.copy(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([A for A in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMOR438_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
