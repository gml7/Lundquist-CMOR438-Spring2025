{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#234567891123456789212345678931234567894123456789512345678961234567897123456789\n",
    "#                                python docstring limit: 72 characters |      \n",
    "#                                            python code limit: 79 characters |\n",
    "# test change\n",
    "class SingleNeuron(object):\n",
    "    \"\"\"\n",
    "    A class used to represent a single neuron (in the machine learning \n",
    "    sense).\n",
    "\n",
    "    Design notes: the model type, the activation function, and the  are \n",
    "    intended to be immutable, though of course python still lets you mutate them.\n",
    "    \"\"\"\n",
    "    type_perceptron = \"perceptron\"\n",
    "    type_linear_regression_1D = \"linear regression 1D\"\n",
    "\n",
    "    def sign(input_value):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        if input_value >= 0:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "    def linear_1D(input_value):\n",
    "        \"\"\" \n",
    "\n",
    "        \"\"\"\n",
    "        return input_value\n",
    "    \n",
    "    default_activation_function = sign\n",
    "\n",
    "    # def test_for_matching_ndarrays(var_1, var_2):\n",
    "    #     return type(var_1) != np.ndarray or type(var_2) != np.ndarray \\\n",
    "    #            or var_1.shape != var_1.shape\n",
    "\n",
    "    def perceptron_loss_function(predicted_outputs, target_outputs):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        # if SingleNeuron.test_for_matching_ndarrays(predicted_values, true_values) == False:\n",
    "        #     raise TypeError\n",
    "        return (1/4) * np.sum((predicted_outputs - target_outputs)**2)\n",
    "    \n",
    "    def perceptron_stochastic_gradient(predicted_output, target_output):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (1/2) * (predicted_output - target_output)\n",
    "\n",
    "    def linear_regression_loss_function(predicted_outputs, target_outputs):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        # if SingleNeuron.test_for_matching_ndarrays(predicted_values, true_values) == False:\n",
    "        #     raise TypeError\n",
    "        return (1/(2*target_outputs.size)) * np.sum((predicted_outputs - target_outputs)**2)\n",
    "        \n",
    "    def linear_regression_1D_stochastic_gradient(predicted_output, target_output, training_data_length):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (1/training_data_length) * (predicted_output - target_output)\n",
    "\n",
    "    def preactivation(input, weights, bias):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return np.dot(input, weights) + bias\n",
    "    \n",
    "    def __init__(self, input_size, model_type=type_perceptron, weights=None, bias=None, \n",
    "                 activation_function=default_activation_function):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        if activation_function != SingleNeuron.default_activation_function:\n",
    "            self.activation_function = activation_function\n",
    "        elif self.model_type == SingleNeuron.type_perceptron:\n",
    "            self.activation_function = SingleNeuron.sign\n",
    "            # though currently the default activation function is sign, \n",
    "            # this allows for future changes\n",
    "        elif self.model_type == SingleNeuron.type_linear_regression_1D:\n",
    "            self.activation_function = SingleNeuron.linear_1D\n",
    "        \n",
    "        if weights == None:\n",
    "            self.weights = np.random.randn(input_size)\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "        if bias == None:\n",
    "            self.bias = np.random.randn()\n",
    "        else:\n",
    "            self.bias = bias\n",
    "\n",
    "    def predict_outputs(self, inputs, weights=None, bias=None, use_current_weights_and_bias=True):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        if use_current_weights_and_bias:\n",
    "            weights = self.weights\n",
    "            bias = self.bias\n",
    "        return [self.activation_function(SingleNeuron.preactivation(input, weights, bias)) for input in inputs]\n",
    "    \n",
    "    def current_weights_and_bias(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return (self.weights.copy(), self.bias.copy())\n",
    "    \n",
    "    def perceptron_stochastic_gradient_update(self, input, target_output, learning_rate=None):\n",
    "        \"\"\" \n",
    "        learning_rate does nothing and is just for making it more uniform to pass around update functions\n",
    "        \"\"\"\n",
    "        gradient = SingleNeuron.perceptron_stochastic_gradient(self.predict_outputs(input), target_output)\n",
    "        self.weights -= gradient * input\n",
    "        self.bias -= gradient\n",
    "        return gradient\n",
    "\n",
    "    def linear_regression_1D_stochastic_gradient_update(self, \n",
    "                input, target_output, learning_rate):\n",
    "        gradient = SingleNeuron.linear_regression_1D_stochastic_gradient(self.predict_outputs(input), target_output)\n",
    "        self.weights -= learning_rate * gradient * input\n",
    "        self.bias -= learning_rate * gradient\n",
    "        return gradient\n",
    "        \n",
    "    def train(self, inputs, target_outputs, learning_rate=0.5, num_epochs=50):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        # if self.model_type != SingleNeuron.type_perceptron and (learning_rate == None or epochs == None):\n",
    "        #     raise ValueError(\"learning_rate and epochs must be specified for non-perceptron models\")\n",
    "        weight_bias_update = None\n",
    "        loss_function = None\n",
    "        if self.model_type == SingleNeuron.type_perceptron:\n",
    "            weight_bias_update = self.perceptron_stochastic_gradient_update\n",
    "            loss_function = SingleNeuron.perceptron_loss_function\n",
    "        elif self.model_type == SingleNeuron.type_linear_regression_1D:\n",
    "            weight_bias_update = self.linear_regression_1D_stochastic_gradient_update\n",
    "            loss_function = SingleNeuron.linear_regression_loss_function\n",
    "\n",
    "        loss_at_epoch = [-1] * (num_epochs + 1)\n",
    "        loss_at_epoch[0] = loss_function(self.predict_outputs(inputs), target_outputs)\n",
    "\n",
    "        for epoch_index in range(num_epochs):\n",
    "            for input, target_output in zip(inputs, target_outputs):\n",
    "                weight_bias_update(input, target_output, learning_rate)\n",
    "            loss_at_epoch[epoch_index+1] = loss_function(self.predict_outputs(inputs), target_outputs)\n",
    "\n",
    "# todo\n",
    "    def __repr__(self):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "# might not be necessary\n",
    "    # def __call__(self):\n",
    "    #     return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the iris dataset from seaborn\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# Filter the dataset to only include 'versicolor' and 'setosa' species\n",
    "filtered_iris = iris[iris['species'].isin(['versicolor', 'setosa'])]\n",
    "\n",
    "# Select only 'sepal_length' and 'sepal_width' variables\n",
    "filtered_iris = filtered_iris[['sepal_length', 'sepal_width', 'species']]\n",
    "\n",
    "# Label 'setosa' as 1 and 'versicolor' as -1\n",
    "filtered_iris['species'] = filtered_iris['species'].map({'setosa': 1, 'versicolor': -1})\n",
    "\n",
    "sepal_size_inputs = filtered_iris[['sepal_length', 'sepal_width']].to_numpy()\n",
    "target_species_output = filtered_iris['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SingleNeuron.__init__() missing 1 required positional argument: 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m neuron_test \u001b[39m=\u001b[39m SingleNeuron()\n",
      "\u001b[1;31mTypeError\u001b[0m: SingleNeuron.__init__() missing 1 required positional argument: 'input_size'"
     ]
    }
   ],
   "source": [
    "neuron_test = SingleNeuron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(3)\n",
    "type(x) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\gabri\\Documents\\Data Science & Machine Learning Spring 2025\\Lundquist-CMOR438-Spring2025\\Single Neuron (draft)\\SingleNeuronClassTesting.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/gabri/Documents/Data%20Science%20%26%20Machine%20Learning%20Spring%202025/Lundquist-CMOR438-Spring2025/Single%20Neuron%20%28draft%29/SingleNeuronClassTesting.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mdot(x,y)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (4,) not aligned: 3 (dim 0) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5437932433939918\n",
      "-1.1348160642001053\n",
      "0.3022609783103276\n"
     ]
    }
   ],
   "source": [
    "for xval in x:\n",
    "    print(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMOR438_base1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
